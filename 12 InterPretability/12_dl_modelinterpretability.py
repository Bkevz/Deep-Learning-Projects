# -*- coding: utf-8 -*-
"""12_DL_ModelInterpretability.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Yd_YzKya1D4K2rCVUm5Jx-GIFHVJET23

##Model Interpretability

##Installing Eli5
"""

!pip install eli5

"""###Importing Libraries"""

from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
import seaborn as sns

"""###Loading Dataset"""

dataset = sns.load_dataset('mpg').dropna()
dataset

"""###Droping Name Column"""

dataset.drop('name', axis =1 , inplace = True)
dataset

"""###Splitting Dataset"""

X_train, X_test, y_train, y_test = train_test_split(dataset.drop('origin', axis = 1), mpg['origin'], test_size = 0.2, random_state = 121)

"""###Model Training"""

model = RandomForestClassifier()
model.fit(X_train, y_train)

"""###ELI5 function to show the classifier weight"""

import eli5
eli5.show_weights(model, feature_names = list(X_test.columns))

"""Note: displacement feature is the most important feature
 but they have a high deviation, indicating bias within the model

###ELI5 function to show the classifier prediction result
"""

eli5.show_prediction(model, X_train.iloc[0])

"""Note: 
Using the show prediction function by ELI5, we could get the feature contribution information. 
What features contribute to certain prediction results, and how much is the probability shifting by these features.

###Black-box model based on the model metric â€” It is called Permutation Importance
"""

from eli5.sklearn import PermutationImportance
perm = PermutationImportance(model, scoring = 'accuracy', random_state=101).fit(X_test, y_test)
eli5.show_weights(perm, feature_names = list(X_test.columns))